{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation_chars_pytorch.ipynb",
      "provenance": [],
      "mount_file_id": "1Q2uXzGiVsSch4QXfIZbwRKs6fixPu3V7",
      "authorship_tag": "ABX9TyM9UIlCoB60Lw8ZH1HrWhOL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bellomusodiq/machine_learning/blob/master/text_generation_chars_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "733E3DXlMorq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZZYTnP_M8zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = os.path.join('drive','My Drive', 'alice.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBRyYDoONgF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = set('hello world')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K07k64SPBnf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "4f643e2e-5e34-4b4b-86f1-c973e326741a"
      },
      "source": [
        "for i in sorted(a): print(i)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            "d\n",
            "e\n",
            "h\n",
            "l\n",
            "o\n",
            "r\n",
            "w\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSXVem5mNPuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dictionary:\n",
        "  def __init__(self):\n",
        "    self.char2idx = {}\n",
        "    self.idx2char = {}\n",
        "\n",
        "  def get_chars(self, file_path):\n",
        "    with open(file_path, mode='r') as f:\n",
        "      for char in sorted(set(f.read())):\n",
        "        if not char in self.char2idx:\n",
        "          self.char2idx[char] = len(self.char2idx)\n",
        "          self.idx2char[len(self.idx2char)] = char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB1xrSL3Oohz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_ = Dictionary()\n",
        "dict_.get_chars(file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcjZgSBgO01X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "32ae709b-29ff-4118-aa13-2cd163043dfb"
      },
      "source": [
        "dict_.idx2char"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\\n',\n",
              " 1: ' ',\n",
              " 2: '!',\n",
              " 3: '\"',\n",
              " 4: \"'\",\n",
              " 5: '(',\n",
              " 6: ')',\n",
              " 7: ',',\n",
              " 8: '-',\n",
              " 9: '.',\n",
              " 10: ':',\n",
              " 11: ';',\n",
              " 12: '?',\n",
              " 13: 'A',\n",
              " 14: 'B',\n",
              " 15: 'C',\n",
              " 16: 'D',\n",
              " 17: 'E',\n",
              " 18: 'F',\n",
              " 19: 'G',\n",
              " 20: 'H',\n",
              " 21: 'I',\n",
              " 22: 'J',\n",
              " 23: 'K',\n",
              " 24: 'L',\n",
              " 25: 'M',\n",
              " 26: 'N',\n",
              " 27: 'O',\n",
              " 28: 'P',\n",
              " 29: 'Q',\n",
              " 30: 'R',\n",
              " 31: 'S',\n",
              " 32: 'T',\n",
              " 33: 'U',\n",
              " 34: 'V',\n",
              " 35: 'W',\n",
              " 36: 'X',\n",
              " 37: 'Y',\n",
              " 38: 'Z',\n",
              " 39: '[',\n",
              " 40: ']',\n",
              " 41: '_',\n",
              " 42: 'a',\n",
              " 43: 'b',\n",
              " 44: 'c',\n",
              " 45: 'd',\n",
              " 46: 'e',\n",
              " 47: 'f',\n",
              " 48: 'g',\n",
              " 49: 'h',\n",
              " 50: 'i',\n",
              " 51: 'j',\n",
              " 52: 'k',\n",
              " 53: 'l',\n",
              " 54: 'm',\n",
              " 55: 'n',\n",
              " 56: 'o',\n",
              " 57: 'p',\n",
              " 58: 'q',\n",
              " 59: 'r',\n",
              " 60: 's',\n",
              " 61: 't',\n",
              " 62: 'u',\n",
              " 63: 'v',\n",
              " 64: 'w',\n",
              " 65: 'x',\n",
              " 66: 'y',\n",
              " 67: 'z'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELeWyzwzPg3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(dict_.char2idx)\n",
        "batch_size = 32\n",
        "rnn_units = 65\n",
        "rnn_layers = 1\n",
        "n_epochs = 20\n",
        "embedding_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m60-N3KiQLrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextGenerator(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, rnn_units, rnn_layers, embedding_size):\n",
        "    super(TextGenerator, self).__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.lstm = nn.LSTM(embedding_size, rnn_units, rnn_layers, batch_first=True)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(.2)\n",
        "    self.output = nn.Linear(rnn_units, vocab_size)\n",
        "\n",
        "  def forward(self, x, h):\n",
        "    embed = self.embed(x)\n",
        "    output, (h_l, c_l) = self.lstm(embed)\n",
        "    # output = self.dropout(output)\n",
        "    output = self.output(output)\n",
        "    return output, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxaWDOZGR7J3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TextGenerator(vocab_size, rnn_units, rnn_layers, embedding_size).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4mWJg8ySB_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "3417c083-73ec-4de6-e982-340859c754fb"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TextGenerator(\n",
            "  (embed): Embedding(68, 32)\n",
            "  (lstm): LSTM(32, 65, batch_first=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (output): Linear(in_features=65, out_features=68, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdpnJcBDV6bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_layers = (\n",
        "    torch.zeros(rnn_layers, batch_size, rnn_units),\n",
        "    torch.zeros(rnn_layers, batch_size, rnn_units)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9iMVi32Wh51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AliceDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, corpus):\n",
        "    sequence_length = 100\n",
        "    num_of_sequence = len(corpus) // (sequence_length + 1)\n",
        "    num_of_chars = num_of_sequence * (sequence_length + 1)\n",
        "    corpus = corpus[:num_of_chars]\n",
        "    self.chunks = [corpus[i:i+sequence_length] for i in range(0, len(corpus), sequence_length+1)]\n",
        "    self.inputs = torch.tensor(self.chunks[:-1], dtype=torch.int64)\n",
        "    self.targets = torch.tensor(self.chunks[1:], dtype=torch.int64)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.inputs[index], self.targets[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNMy3AzliS5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "with open(file_path, mode='r') as f:\n",
        "  for char in f.read():\n",
        "    corpus.append(dict_.char2idx[char])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXuPpYO2ch5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = AliceDataset(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIe3gya0ioQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkv3DAMDrI03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz0ng5kup9bC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "5dd88f30-0f38-447f-c02b-a377c5a59a24"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "  h = (\n",
        "      torch.zeros(rnn_layers, batch_size, rnn_units).cuda(),\n",
        "      torch.zeros(rnn_layers, batch_size, rnn_units).cuda()\n",
        "  )\n",
        "  for features, targets in data_loader:\n",
        "    output, h = model(features.cuda(), h)\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(output.transpose(1,2).cuda(), targets.cuda())\n",
        "    state_h = h[0].detach()\n",
        "    state_c = h[1].detach()\n",
        "    h = state_h, state_c\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), .5)\n",
        "  print('Epoch:', epoch+1, 'loss:', loss.item())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 loss: 3.094210624694824\n",
            "Epoch: 2 loss: 3.1157679557800293\n",
            "Epoch: 3 loss: 3.1881818771362305\n",
            "Epoch: 4 loss: 3.1403088569641113\n",
            "Epoch: 5 loss: 3.1528947353363037\n",
            "Epoch: 6 loss: 3.1644368171691895\n",
            "Epoch: 7 loss: 3.256956100463867\n",
            "Epoch: 8 loss: 3.235138177871704\n",
            "Epoch: 9 loss: 3.138655185699463\n",
            "Epoch: 10 loss: 3.257835865020752\n",
            "Epoch: 11 loss: 3.2225089073181152\n",
            "Epoch: 12 loss: 3.18119478225708\n",
            "Epoch: 13 loss: 3.1715281009674072\n",
            "Epoch: 14 loss: 3.136408567428589\n",
            "Epoch: 15 loss: 3.1786770820617676\n",
            "Epoch: 16 loss: 3.1374247074127197\n",
            "Epoch: 17 loss: 3.145899534225464\n",
            "Epoch: 18 loss: 3.356417655944824\n",
            "Epoch: 19 loss: 3.135282278060913\n",
            "Epoch: 20 loss: 3.1834447383880615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBlfKkS-zMUq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "d25070de-e309-4c06-b47f-4f14789cb452"
      },
      "source": [
        "with torch.no_grad():\n",
        "  with open('results.txt', 'w') as f:\n",
        "    state = (\n",
        "        torch.zeros(1, 1, rnn_units).cuda(),\n",
        "        torch.zeros(1, 1, rnn_units).cuda(),\n",
        "    )\n",
        "    input_ = [0]\n",
        "    \n",
        "    for i in range(500):\n",
        "      x = torch.tensor([input_], dtype=torch.int64).cuda()\n",
        "      output, state = model(x, state)\n",
        "      prob = output.squeeze(1).exp()\n",
        "      word_id = torch.multinomial(prob, num_samples=1).item()\n",
        "      input.append(word_id)\n",
        "\n",
        "      word = dict_.idx2char[word_id]\n",
        "      f.write(word)\n",
        "\n",
        "      if (i+1) % 100 == 0:\n",
        "        print('Sampled {}/{}'.format(i, 500))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-b9ae63ef3895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mword_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'append'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x--CmMz53Jok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  out = model(torch.tensor([[1,2,22,54]], dtype=torch.int64).cuda(), state)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}